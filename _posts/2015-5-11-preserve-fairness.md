---
layout: post
category : fairness 
tags : [review,article,indirect discrimination]
title : In media -- Ways to preserve fairness when algorithms are making decisions
---
{% include JB/setup %}

Virginia Eubanks in [a recent article in Slate](http://www.slate.com/articles/technology/future_tense/2015/04/the_dangers_of_letting_algorithms_enforce_policy.single.html)[^1]
discusses problems with "black-box" algorithms making decisions in law enforcement, welfare, and child protection.

> The algorithms that dominate policymaking — particularly in public services such as law enforcement, welfare, and child protection — act less like data sifters and more like gatekeepers, mediating access to public resources, assessing risks, and sorting groups of people into “deserving” and “undeserving” and “suspicious” and “unsuspicious” categories.

The article suggest several means for preserve fairness in automated decision-making.

> 1) Learning more about how policy algorithms work.

This says that algorithms need to be transparent, it should be possible to trace how decisions are made. Eubanks suggests to perform *algorithmic-audits*.

> 2) Addressing the political context of algorithms.

Basically, algorithmic tasks should be formulated in a clean way without political predisposition, and algorithms themselves need to be sanitized. 

> 3) Address how cumulative disadvantage sediments in algorithms.

This is about accumulation of unfairness over time, from data biases get into algorithms, and from algorithms they are pushed into next data. 

> 4) Respecting constitutional principles, enforcing legal rights, and strengthening due process procedures.

This is about making clear, who takes the reponsibility for decisions made by algorithms.

In summary, Eubanks is saying that algorithms should be transparent, sanitized, and there should be humans behind, responsibl for the decisions.

Algorithmic research is just starting to address the first two points. 
As for humans, I don't think it is realistically possible to allocate responsibilities for each decision, because then, why use algorithms.  


[^1] I first saw a pointer to it at [FlowingData](http://flowingdata.com/).